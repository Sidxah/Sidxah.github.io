- title: General Information
  type: map
  contents:
    - name: Full Name
      value: Sid Ahmed Bouamama
    - name: Email
      value: sidahmedbouamama@gmail.com
    - name: Location
      value: Île-de-France, France
    - name: Languages
      value: French (Native), English (Bilingual), Arabic (Native)

- title: Education
  type: time_table
  contents:
    - title: Master 1 – Quantum & Distributed Computer Science (QDCS)
      institution: Université Paris-Saclay, Orsay, France
      year: 2024 – 2026
      description:
        - "Mathematics for Data Science: 20.75/20"
        - "Relevant Coursework: Machine Learning, Statistical Learning, Optimization, High-Performance Computing, Deep Learning"
        - "Self-Directed: Stanford CS231n, Deep Learning Specialization (deeplearning.ai)"

    - title: Double Licence Mathématiques & Informatique
      institution: Université Sorbonne Paris Nord – Institut Galilée, Villetaneuse, France
      year: 2021 – 2024
      description:
        - "Rank: Top 7 across all Mathematics and Computer Science programs (L3)"
        - "Key Grades: Functional Programming (20/20), Linear Algebra (16/20)"
        - "Overall: L1: 14.73/20 (Bien) — L2: 15.29/20 (Bien)"

- title: Research Experience
  type: time_table
  contents:
    - title: TER Research Project – Fine-Grained Text Supervision in CLIP
      institution: CEA LIST (LASTI Lab), Université Paris-Saclay
      year: Jan – Apr 2026
      description:
        - "Supervisor: Prof. Adrian Popescu"
        - "Investigating the effect of fine-grained textual descriptions on CLIP-style multimodal representation learning"
        - "Collaboration with PhD candidate Mehdi Zakaria Adjal"

    - title: CLIP Implementation from Scratch
      institution: Self-Directed Research Project
      year: Oct 2025 – Present
      description:
        - "Reproducing Radford et al. (2021) to understand vision-language alignment"
        - "ResNet-50 vision encoder + Transformer text encoder from scratch"
        - "Achieved 76%+ zero-shot accuracy on CIFAR-10"

- title: Professional Experience
  type: time_table
  contents:
    - title: AI Research Engineer (CDD)
      institution: PyxiScience – AI-Powered Adaptive Learning Platform, Paris (Station F)
      year: Aug 2025 – Present
      description:
        - "Designed systematic LLM evaluation framework comparing GPT-4, Gemini, and DeepSeek"
        - "Developed two-stage prompt engineering methodology, improving content quality by 40%"
        - "Implemented AST-based code analysis and automated hallucination detection"
        - "Working under Jacques Lévy Véhel (former INRIA Research Director, 4,200+ citations)"

    - title: Data Science Intern
      institution: PyxiScience, Paris
      year: May – Aug 2025
      description:
        - "Developed prompt optimization pipelines improving exercise generation accuracy by 35%"
        - "Implemented automated LaTeX parsing and validation systems"

- title: Achievements
  type: time_table
  contents:
    - title: Top 3 / 400+ participants
      institution: Hi! Paris Hackathon 2025 – PISA Education Data Challenge
      year: 2025
      description:
        - "Polytechnique × HEC"
        - "Built ensemble ML models (XGBoost, LightGBM) predicting student MathScore"
        - "Advanced feature engineering on 1.7M records with 50%+ missing data"

    - title: Top 20 / 200+ participants
      institution: Hi! Paris Hackathon 2024 – AI & Sustainability
      year: 2024
      description:
        - "Developed ML model for groundwater level forecasting"
        - "Applied temporal feature engineering and AutoGluon ensemble optimization"

- title: Technical Skills
  type: nested_list
  contents:
    - title: Deep Learning
      items:
        - PyTorch, torchvision, Hugging Face Transformers, TensorFlow
    - title: ML & Data Science
      items:
        - Scikit-learn, XGBoost, LightGBM, AutoGluon, Optuna, Pandas, NumPy
    - title: Programming
      items:
        - Python, C/C++, SQL, Java, OCaml, Git, Linux, Docker
    - title: Concepts
      items:
        - CNNs, Transformers, Self-Supervised Learning (CLIP, SimCLR, MAE, I-JEPA, DINO)
        - Contrastive Learning, Vision-Language Models, Object Detection

- title: Research Interests
  type: list
  contents:
    - Self-Supervised & Data-Efficient Learning
    - Vision-Language Alignment & Contrastive Learning
    - Computer Vision & Multimodal AI
    - Few-Shot Learning & Robustness to Distribution Shifts
