---
layout: about
title: About
permalink: /
subtitle: M1 QDCS • <a href="https://www.universite-paris-saclay.fr/">Paris-Saclay University</a>

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false
  more_info: >
    <p>Île-de-France, France</p>
    <p>sidahmedbouamama@gmail.com</p>

news: true
selected_papers: false
social: true
---

I am a first-year Master's student in **Quantum and Distributed Computer Science (QDCS)** at [Paris-Saclay University](https://www.universite-paris-saclay.fr/), with a strong focus on **Artificial Intelligence**, **Computer Vision**, and **Self-Supervised Learning**.

My research interests lie at the intersection of **deep learning** and **multimodal representation learning**. I am particularly interested in exploring how vision-language models like CLIP can learn from weak textual supervision, and how self-supervised methods can enable data-efficient learning mechanisms.

## Background

I hold a **Double Bachelor's degree in Mathematics and Computer Science** from [Sorbonne Paris Nord University](https://www.univ-paris13.fr/), where I ranked **5th out of 105 students** (GPA: 3.5/4.0). This dual training provided me with solid foundations in both theoretical mathematics and practical computer science.

During my studies, I completed an internship as an **AI Engineer at PyxiScience** (Station F, Paris), where I designed evaluation frameworks for comparing large language models (GPT-4, Gemini, DeepSeek) on mathematical reasoning tasks. I developed advanced prompting methodologies that improved content quality by 40%.

## Current Work

I am currently working on:

- **CLIP Implementation from Scratch**: Reproducing the CLIP model (Radford et al., 2021) to deeply understand contrastive vision-language learning. [GitHub →](https://github.com/Sidxah)
  
- **Bayesian Image Super-Resolution**: Implementing modern approaches to image super-resolution using Bayesian deep learning principles.

- **Preparing a TER (Master's Research Project)** on self-supervised learning for computer vision, focusing on temporal consistency as a supervision signal.

## Technical Skills

**Programming**: Python, C/C++, Java, OCaml, SQL, Git, Linux, Docker

**AI & ML**: PyTorch, Hugging Face Transformers, Scikit-learn, LangChain, Prompt Engineering

**Concepts**: CNNs, Transformers, Self-Supervised Learning, Contrastive Learning, Vision-Language Models

## Languages

- **French**: Native
- **English**: Bilingual (research & academic)
- **Arabic**: Native
