---
layout: page
title: AI-Powered Educational Content Generation
description: LLM evaluation framework and automated content generation at PyxiScience
img: 
importance: 1
category: AI & Machine Learning
---

## Overview

During my internship at **PyxiScience** (Station F, Paris), I developed an automated educational content generation system with a focus on LLM evaluation and optimization.

## Key Contributions

### 1. LLM Evaluation Framework
Designed a systematic framework comparing **GPT-4**, **Gemini**, and **DeepSeek** on mathematical reasoning tasks:
- Analyzed trade-offs in accuracy, hallucination rates, and inference costs
- Established benchmarks for educational content quality

### 2. Advanced Prompt Engineering
Developed a **two-stage prompting methodology**:
- Stage 1: Pedagogical constraint integration
- Stage 2: Technical formatting requirements
- **Result**: 40% improvement in content quality

### 3. Quality Assessment Pipeline
- AST-based code analysis for exercise validation
- Automated hallucination detection with weighted scoring
- **Result**: 60% reduction in manual review time

### 4. System Architecture
Built a scalable parallel AI pipeline with asynchronous API handling for high-throughput content generation.

## Technologies

`Python` `OpenAI API` `Google Gemini` `DeepSeek` `LangChain` `RAG` `Prompt Engineering`

## Impact

The system serves **10,000+ active students** across European universities, contributing to an **85% improvement** in student performance metrics.

## Period

**2025** â€” AI Engineer Intern, PyxiScience, Station F, Paris
